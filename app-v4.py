import streamlit as st
import zipfile
import tempfile
import os
import json
import pandas as pd
import torch
import numpy as np
from PIL import Image
import requests
from io import BytesIO
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode

st.set_page_config(page_title="PT Metadata Manager", layout="wide")
st.title("ğŸ“¦ PT ë©”íƒ€ë°ì´í„° ZIP ì—…ë¡œë“œ ë° ì‹œê°í™”")

uploaded_zip = st.file_uploader("ğŸ’¾ pt_metadata.zip íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="zip")

if uploaded_zip:
    with tempfile.TemporaryDirectory() as tmpdir:
        zip_path = os.path.join(tmpdir, "pt_metadata.zip")
        with open(zip_path, "wb") as f:
            f.write(uploaded_zip.read())

        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(tmpdir)

        # JSON íŒŒì¼ ì½ê¸°
        all_meta = []
        for root, _, files in os.walk(tmpdir):
            for file in files:
                if file.endswith(".json"):
                    try:
                        with open(os.path.join(root, file), "r", encoding="utf-8") as f:
                            all_meta.extend(json.load(f))
                    except Exception as e:
                        st.error(f"âŒ {file} ì˜¤ë¥˜: {e}")

        if not all_meta:
            st.warning("âš ï¸ ë¡œë”©ëœ ë©”íƒ€ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        st.success(f"âœ… ì´ {len(all_meta)}ê°œ ë©”íƒ€ì •ë³´ ë¡œë”© ì™„ë£Œ")

        df = pd.DataFrame(all_meta)

        # í†µê³„ ì‹œê°í™”
        st.subheader("ğŸ“Š Labelë³„ ë¶„í¬")
        st.bar_chart(df['label'].value_counts())

        st.subheader("ğŸ›  Table IDë³„ ë¶„í¬")
        st.line_chart(df['table_id'].value_counts().sort_index())

        st.subheader("ğŸ“ˆ Table ID x Label êµì°¨í‘œ")
        st.dataframe(pd.crosstab(df['table_id'], df['label']))

        # í•„í„°ë§ UI
        st.sidebar.header("ğŸ” í•„í„° ì¡°ê±´")
        table_ids = sorted(df['table_id'].dropna().unique())
        labels = sorted(df['label'].dropna().unique())
        selected_table = st.sidebar.selectbox("Table ID ì„ íƒ", [None] + list(table_ids))
        selected_label = st.sidebar.selectbox("Label ì„ íƒ", [None] + list(labels))

        filtered_df = df.copy()
        if selected_table is not None:
            filtered_df = filtered_df[filtered_df['table_id'] == selected_table]
        if selected_label is not None:
            filtered_df = filtered_df[filtered_df['label'] == selected_label]

        st.subheader("ğŸ“‚ í•„í„°ë§ ê²°ê³¼")
        st.write(f"ğŸ” ì¡°ê±´ì— ë§ëŠ” íŒŒì¼: {len(filtered_df)}ê°œ")

        # AgGridì—ì„œ í–‰ ì„ íƒ
        gb = GridOptionsBuilder.from_dataframe(filtered_df)
        gb.configure_selection('single')
        grid_options = gb.build()
        grid_response = AgGrid(
            filtered_df,
            gridOptions=grid_options,
            update_mode=GridUpdateMode.SELECTION_CHANGED,
            height=300,
            width='100%',
            allow_unsafe_jscode=True,
        )

        selected = grid_response.get('selected_rows', [])
        if isinstance(selected, list) and len(selected) > 0:
            selected_filename = selected[0].get('filename')

            if selected_filename:
                st.subheader("ğŸ“ ì„ íƒí•œ .pt íŒŒì¼ ìƒì„¸ ì •ë³´")
                folder_id = st.text_input("ğŸ“‚ Google Drive ê³µìœ  í´ë” ID (processed_segments)", "")

                def build_gdrive_download_url(folder_id, filename):
                    return f"https://drive.google.com/uc?export=download&id={folder_id}&filename={filename}"

                if folder_id:
                    gdrive_url = f"https://drive.google.com/uc?export=download&id={folder_id}&confirm=t"
                    try:
                        with st.spinner("ğŸ“¥ .pt íŒŒì¼ ë¡œë”© ì¤‘..."):
                            response = requests.get(gdrive_url)
                            pt_data = torch.load(BytesIO(response.content), map_location="cpu")

                            # ì´ë¯¸ì§€ í…ì„œ í™•ì¸ ë° ì‹œê°í™”
                            img_tensor = pt_data.get("image_tensor")
                            if img_tensor is not None:
                                img_np = img_tensor.permute(1, 2, 0).detach().cpu().numpy()
                                st.write("ğŸ“Š image_tensor value range:", img_np.min(), "~", img_np.max())
                                if img_np.max() <= 1.0:
                                    img_np = (img_np * 255).astype(np.uint8)
                                else:
                                    img_np = img_np.astype(np.uint8)
                                st.image(img_np, caption="ğŸ“¸ image_tensor preview")
                            else:
                                st.info("â„¹ï¸ image_tensor ì—†ìŒ")

                            # ì‹œí€€ìŠ¤ ë°ì´í„°
                            hand_seq = pt_data.get("hand_sequence")
                            if hand_seq is not None:
                                st.subheader("âœ‹ Hand Sequence")
                                df_hand = pd.DataFrame(hand_seq.numpy())
                                st.line_chart(df_hand.iloc[:, :5])
                            else:
                                st.info("â„¹ï¸ hand_sequence ì—†ìŒ")

                            pneu_seq = pt_data.get("pneumatic_sequence")
                            if pneu_seq is not None:
                                st.subheader("ğŸ”§ Pneumatic Sequence")
                                df_pneu = pd.DataFrame(pneu_seq.numpy())
                                st.line_chart(df_pneu.iloc[:, :5])
                            else:
                                st.info("â„¹ï¸ pneumatic_sequence ì—†ìŒ")
                    except Exception as e:
                        st.error(f"âŒ .pt íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {e}")

        # CSV ë‹¤ìš´ë¡œë“œ
        csv_data = filtered_df.to_csv(index=False).encode('utf-8')
        st.download_button("ğŸ“¥ í•„í„° ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", data=csv_data, file_name="filtered_metadata.csv", mime="text/csv")
