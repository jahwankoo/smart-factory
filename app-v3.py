import streamlit as st
import zipfile
import tempfile
import os
import json
import pandas as pd
import matplotlib.pyplot as plt
import torch
import numpy as np
from PIL import Image
import time
import requests
from io import BytesIO

st.set_page_config(page_title="PT Metadata Manager", layout="wide")
st.title("ğŸ“¦ PT ë©”íƒ€ë°ì´í„° ZIP ì—…ë¡œë“œ ë° ì‹œê°í™”")

uploaded_zip = st.file_uploader("ğŸ’¾ pt_metadata.zip íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="zip")

if uploaded_zip:
    with tempfile.TemporaryDirectory() as tmpdir:
        zip_path = os.path.join(tmpdir, "pt_metadata.zip")
        with open(zip_path, "wb") as f:
            f.write(uploaded_zip.read())

        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(tmpdir)

        # JSON íŒŒì¼ ì½ê¸°
        all_meta = []
        for root, _, files in os.walk(tmpdir):
            for file in files:
                if file.endswith(".json"):
                    try:
                        with open(os.path.join(root, file), "r", encoding="utf-8") as f:
                            all_meta.extend(json.load(f))
                    except Exception as e:
                        st.error(f"âŒ {file} ì˜¤ë¥˜: {e}")

        if not all_meta:
            st.warning("âš ï¸ ë¡œë”©ëœ ë©”íƒ€ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        st.success(f"âœ… ì´ {len(all_meta)}ê°œ ë©”íƒ€ì •ë³´ ë¡œë”© ì™„ë£Œ")

        # DataFrame ë³€í™˜
        df = pd.DataFrame(all_meta)

        # í†µê³„ ì‹œê°í™”
        st.subheader("ğŸ“Š Labelë³„ ë¶„í¬")
        label_counts = df['label'].value_counts()
        st.bar_chart(label_counts)

        st.subheader("ğŸ›  Table IDë³„ ë¶„í¬")
        table_counts = df['table_id'].value_counts().sort_index()
        st.line_chart(table_counts)

        st.subheader("ğŸ“ˆ Table ID x Label êµì°¨í‘œ")
        cross = pd.crosstab(df['table_id'], df['label'])
        st.dataframe(cross)

        # í•„í„°ë§
        st.sidebar.header("ğŸ” í•„í„° ì¡°ê±´")
        table_ids = sorted(df['table_id'].dropna().unique())
        labels = sorted(df['label'].dropna().unique())

        selected_table = st.sidebar.selectbox("Table ID ì„ íƒ", [None] + list(table_ids))
        selected_label = st.sidebar.selectbox("Label ì„ íƒ", [None] + list(labels))

        filtered_df = df.copy()
        if selected_table is not None:
            filtered_df = filtered_df[filtered_df['table_id'] == selected_table]
        if selected_label is not None:
            filtered_df = filtered_df[filtered_df['label'] == selected_label]

        st.subheader("ğŸ“‚ í•„í„°ë§ ê²°ê³¼")
        st.write(f"ğŸ” ì¡°ê±´ì— ë§ëŠ” íŒŒì¼: {len(filtered_df)}ê°œ")
        st.dataframe(filtered_df, use_container_width=True)

        # Google Drive ë§í¬ ê¸°ë°˜ .pt íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
        st.subheader("ğŸ”— Google Drive ë§í¬ ê¸°ë°˜ .pt íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°")
        selected_row = st.selectbox("ğŸ” ë©”íƒ€ì •ë³´ì—ì„œ íŒŒì¼ ì„ íƒ", filtered_df.to_dict("records"))

        def gdrive_to_direct_url(share_url):
            if "/d/" in share_url:
                file_id = share_url.split("/d/")[1].split("/")[0]
            elif "id=" in share_url:
                file_id = share_url.split("id=")[1].split("&")[0]
            else:
                return None
            return f"https://drive.google.com/uc?export=download&id={file_id}"

        gdrive_link = st.text_input("ğŸ“ Google Drive ê³µìœ  ë§í¬ (.pt íŒŒì¼)")

        if gdrive_link:
            pt_url = gdrive_to_direct_url(gdrive_link)
            try:
                with st.spinner("ğŸ“¥ .pt íŒŒì¼ ë¡œë”© ì¤‘..."):
                    response = requests.get(pt_url)
                    pt_data = torch.load(BytesIO(response.content), map_location="cpu")

                    # ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°
                    img_tensor = pt_data.get("image_tensor")
                    if img_tensor is not None:
                        img_np = img_tensor.permute(1, 2, 0).numpy().astype(np.uint8)
                        st.image(img_np, caption="ğŸ“¸ image_tensor preview")
                    else:
                        st.info("â„¹ï¸ image_tensor ì—†ìŒ")

                    # ì† ì‹œí€€ìŠ¤
                    hand_seq = pt_data.get("hand_sequence")
                    if hand_seq is not None:
                        st.subheader("âœ‹ Hand Sequence Preview")
                        df_hand = pd.DataFrame(hand_seq.numpy())
                        st.line_chart(df_hand.iloc[:, :5])
                    else:
                        st.info("â„¹ï¸ hand_sequence ì—†ìŒ")

                    # ê³µì•• ì‹œí€€ìŠ¤
                    pneu_seq = pt_data.get("pneumatic_sequence")
                    if pneu_seq is not None:
                        st.subheader("ğŸ”§ Pneumatic Sequence Preview")
                        df_pneu = pd.DataFrame(pneu_seq.numpy())
                        st.line_chart(df_pneu.iloc[:, :5])
                    else:
                        st.info("â„¹ï¸ pneumatic_sequence ì—†ìŒ")

            except Exception as e:
                st.error(f"âŒ .pt íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {e}")

        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        csv_data = filtered_df.to_csv(index=False).encode('utf-8')
        st.download_button("ğŸ“¥ í•„í„° ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", data=csv_data, file_name="filtered_metadata.csv", mime="text/csv")
